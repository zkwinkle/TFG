\chapter{Marco de referencia teórico}

Este capítulo introduce los conceptos teóricos necesarios para respaldar este
proyecto, el cual se sitúa en la intersección entre las áreas de ALS y ML. La
integración de estas disciplinas permite explorar nuevos métodos para la
generación de circuitos digitales que intercambien exactitud por eficiencia y
complejidad.

Se introducen conceptos fundamentales de ML, necesarios para entender los
mecanismos mediante los cuales un modelo puede ser útil en la generación de
circuitos aproximados, siendo especialmente relevante su capacidad para
aprender y generalizar funciones booleanas. Por otro lado, se revisan los
conceptos básicos de la computación aproximada y las técnicas tradicionales de
ALS, con el objetivo de contrastarlas con los enfoques basados en ML.

Finalmente, se abordan técnicas para transformar modelos de ML que han
aprendido funciones booleanas en circuitos lógicos, paso necesario para su
aplicación práctica dentro del marco de ALS.

La Figura \ref{fig:mapa_conceptual} mapea los conceptos tratados en
este capítulo en un mapa conceptual.

\begin{figure}[ht]
  \centering
  \includesvg[width=0.85\linewidth]{./imágenes/Mapa conceptual.svg}
  \caption{Mapa conceptual de los temas abordados en el marco teórico. Las burbujas rojas corresponden a temas asociados a ML, las burbujas azules corresponden a temas asociados a ALS y las burbujas moradas corresponden a temas que integran las 2 áreas.}
  \label{fig:mapa_conceptual}
\end{figure}

\section{Aprendizaje Automático}

Según Russel y Norvig \cite{russell2016artificial}, en el aprendizaje automático una computadora analiza datos, construye un modelo
basado en esos datos y luego usa ese modelo tanto como una hipótesis sobre el
mundo como una herramienta de software para resolver problemas.

En el contexto de ALS, una de las formas que más nos interesa aplicar ML es
que la computadora analice los datos de la tabla de verdad de un circuito,
de modo que se construya una representación generalizada del comportamiento de
dicho circuito.
Este modelo actúa como una hipótesis sobre lo que haría el circuito original, y
aunque normalmente en otros enfoques de ML se mantendría como una solución en
software, en nuestro caso buscamos transformarlo en hardware. De esta forma, el
modelo sigue funcionando como una hipótesis de lo que haría el circuito
original, pero implementada directamente como un circuito aproximado.

\subsection{Aprendizaje supervisado}

En el aprendizaje supervisado, el agente observa parejas de entradas y salidas
y aprende una función que mapea las entradas a sus correspondientes salidas
\cite{russell2016artificial}.

Es decir, en el aprendizaje supervisado, se dispone de los datos del
comportamiento que se desea aprender antes del entrenamiento.

Un ejemplo de esto, en el contexto de ALS, es cuando se entrena un modelo
utilizando la tabla de verdad de un circuito, que es un conjunto de datos que
muestra las salidas correspondientes a sus entradas.

\subsection{Aprendizaje reforzado}

El aprendizaje reforzado es aprender qué hacer o cómo asociar situaciones con
acciones, para maximizar una señal de recompensa. No se le dice al agente qué
acciones tomar, sino que debe descubrir cuáles acciones dan la mayor recompensa
mediante prueba y error. \cite{sutton_reinforcement_2018}

En el contexto de ALS, un agente RL podría ser entrenado para aprender a
modificar un circuito, realizando modificaciones y recibiendo una recompensa
basado en parámetros como la reducción en área, en tiempo de ejecución, o el
aumento en el error del circuito. Así el agente, después de mucho entrenamiento
se convertirá en un experto en realizar modificaciones a circuitos para generar
versiones aproximadas de ellos.

\subsection{Generalización}

Según Bishop \cite{bishop_pattern_2006}, en el contexto de ML, la
generalización es la capacidad de un modelo para producir respuestas correctas
ante entradas no vistas durante el entrenamiento. En la práctica, el espacio de
posibles entradas suele ser tan amplio que el conjunto de entrenamiento solo
representa una pequeña fracción del total.

Por ejemplo, un modelo entrenado para distinguir entre fotos de gatos y perros
no puede haber visto todas las imágenes de estos animales en la existencia;
debe aprender patrones generales (es decir, debe generalizar), para poder
clasificar imágenes nuevas.

En el contexto de la síntesis lógica aproximada (ALS), si bien es posible
generar todas las combinaciones de entrada/salida de la tabla de verdad para
circuitos pequeños, esto se vuelve inviable a medida que el número de entradas
crece. Un circuito con 64 bits de entrada tiene $2^{64}$ combinaciones
posibles, aproximadamente \num{1.8e19}, lo que hace imposible utilizar su tabla
de verdad completa. Por tanto, el modelo debe aprender a generalizar a partir
de un subconjunto representativo. Incluso en circuitos pequeños, donde es
posible entrenar modelos con una tabla de verdad exhaustiva, el modelo no
memoriza los datos, sino que generaliza al construir una representación
abstracta del circuito basada en patrones presentes en los ejemplos.

\subsection{Sobreajuste}

\subsection{Validación de modelos}

\subsection{Modelos y técnicas}

\subsubsection{Bosque aleatorio (RF)}

\subsubsection{Redes de tablas de búsqueda (LUTs)}

\subsubsection{Perceptrón multicapa / Red neuronal}

\subsubsection{Programación genética cartesiana (CGP)}

\section{Computación Aproximada}

\subsection{Síntesis Lógica Aproximada}

Definición y características

\subsection{Métodos clásicos}

Principios teóricos

\subsection{Métricas de error}

\subsection{Síntesis de modelos de ML}

\subsubsection{Diagramas de decisión binarios}

\subsubsection{Bosques de decisión}

\subsubsection{Redes neuronales}
