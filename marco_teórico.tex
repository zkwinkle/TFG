\chapter{Marco de referencia teórico}

Este capítulo introduce los conceptos teóricos necesarios para respaldar este
proyecto, el cual se sitúa en la intersección entre las áreas de ALS y ML. La
integración de estas disciplinas permite explorar nuevos métodos para la
generación de circuitos digitales que intercambien exactitud por eficiencia y
complejidad.

Se introducen conceptos fundamentales de ML, necesarios para entender los
mecanismos mediante los cuales un modelo puede ser útil en la generación de
circuitos aproximados, siendo especialmente relevante su capacidad para
aprender y generalizar funciones booleanas. Por otro lado, se revisan los
conceptos básicos de la computación aproximada y las técnicas tradicionales de
ALS, con el objetivo de contrastarlas con los enfoques basados en ML.

Finalmente, se abordan técnicas para transformar modelos de ML que han
aprendido funciones booleanas en circuitos lógicos, paso necesario para su
aplicación práctica dentro del marco de ALS.

La Figura \ref{fig:mapa_conceptual} mapea los conceptos tratados en
este capítulo en un mapa conceptual.

\begin{figure}[ht]
  \centering
  \includesvg[width=0.85\linewidth]{./imágenes/Mapa conceptual.svg}
  \caption{Mapa conceptual de los temas abordados en el marco teórico. Las
    burbujas rojas corresponden a temas asociados a ML, las burbujas azules
    corresponden a temas asociados a ALS y las burbujas moradas corresponden a
  temas que integran las 2 áreas.}
  \label{fig:mapa_conceptual}
\end{figure}

\section{Aprendizaje Automático}

Según Russel y Norvig \cite{russell2016artificial}, en el aprendizaje
automático una computadora analiza datos, construye un modelo basado en esos
datos y luego usa ese modelo tanto como una hipótesis sobre el mundo como una
herramienta de software para resolver problemas.

En el contexto de ALS, una de las formas que más nos interesa aplicar ML es
que la computadora analice los datos de la tabla de verdad de un circuito,
de modo que se construya una representación generalizada del comportamiento de
dicho circuito.
Este modelo actúa como una hipótesis sobre lo que haría el circuito original, y
aunque normalmente en otros enfoques de ML se mantendría como una solución en
software, en nuestro caso buscamos transformarlo en hardware. De esta forma, el
modelo sigue funcionando como una hipótesis de lo que haría el circuito
original, pero implementada directamente como un circuito aproximado.

\subsection{Aprendizaje supervisado}

En el aprendizaje supervisado, el agente observa parejas de entradas y salidas
y aprende una función que mapea las entradas a sus correspondientes salidas
\cite{russell2016artificial}.

Es decir, en el aprendizaje supervisado, se dispone de los datos del
comportamiento que se desea aprender antes del entrenamiento.

Un ejemplo de esto, en el contexto de ALS, es cuando se entrena un modelo
utilizando la tabla de verdad de un circuito, que es un conjunto de datos que
muestra las salidas correspondientes a sus entradas.

\subsection{Aprendizaje reforzado}

El aprendizaje reforzado es aprender qué hacer o cómo asociar situaciones con
acciones, para maximizar una señal de recompensa. No se le dice al agente qué
acciones tomar, sino que debe descubrir cuáles acciones dan la mayor recompensa
mediante prueba y error. \cite{sutton_reinforcement_2018}

En el contexto de ALS, un agente RL podría ser entrenado para aprender a
modificar un circuito, realizando modificaciones y recibiendo una recompensa
basado en parámetros como la reducción en área, en tiempo de ejecución, o el
aumento en el error del circuito. Así el agente, después de mucho entrenamiento
se convertirá en un experto en realizar modificaciones a circuitos para generar
versiones aproximadas de ellos.

\subsection{Generalización}

Según Bishop \cite{bishop_pattern_2006}, en el contexto de ML, la
generalización es la capacidad de un modelo para producir respuestas correctas
ante entradas no vistas durante el entrenamiento. En la práctica, el espacio de
posibles entradas suele ser tan amplio que el conjunto de entrenamiento solo
representa una pequeña fracción del total.

Por ejemplo, un modelo entrenado para distinguir entre fotos de gatos y perros
no puede haber visto todas las imágenes de estos animales en la existencia;
debe aprender patrones generales (es decir, debe generalizar), para poder
clasificar imágenes nuevas.

En el contexto de la síntesis lógica aproximada (ALS), si bien es posible
generar todas las combinaciones de entrada/salida de la tabla de verdad para
circuitos pequeños, esto se vuelve inviable a medida que el número de entradas
crece. Un circuito con 64 bits de entrada tiene $2^{64}$ combinaciones
posibles, aproximadamente \num{1.8e19}, lo que hace imposible utilizar su tabla
de verdad completa. Por tanto, el modelo debe aprender a generalizar a partir
de un subconjunto representativo. Incluso en circuitos pequeños, donde es
posible entrenar modelos con una tabla de verdad exhaustiva, el modelo no
memoriza los datos, sino que generaliza al construir una representación
abstracta del circuito basada en patrones presentes en los ejemplos.

\subsection{Sobreajuste}

Se dice que una función aprendida tiene sobreajuste cuando presta demasiada
atención al conjunto de datos con el que fue entrenada, lo que provoca un mal
desempeño con datos no vistos \cite{russell2016artificial}.

En el contexto de aprendizaje de circuitos, el sobreajuste puede ocurrir si un
modelo memoriza las entradas y salidas de un subconjunto limitado de la tabla
de verdad, sin capturar el comportamiento general del circuito. Como resultado,
puede fallar al predecir correctamente salidas para combinaciones de entrada no
vistas, aunque estas sigan la misma lógica.

\subsection{Validación de modelos}

La validación de modelos es el proceso de confirmar que un modelo produce
resultados suficientemente correctos para el propósito con el que fue diseñado,
dentro del dominio en el que se aplica \cite{schlesinger_terminology_1979}.

En el dominio de ML, esta validación comúnmente se lleva a cabo separando los
datos de entrenamiento en 3 conjuntos:

\begin{itemize}
  \item Un conjunto de entrenamiento, utilizado para entrenar los modelos
  \item Un conjunto de validación, que se utiliza para evaluar los modelos
    entrenados y ver que generalicen bien y no tengan sobreajuste. Se puede
    utilizar para entrenar múltiples modelos similares y escoger el que tenga
    mejor rendimiento.
  \item Un conjunto de prueba para realizar una evaluación final e imparcial
    del modelo \cite{russell2016artificial}.
\end{itemize}

A pesar de los nombres utilizados para los conjuntos, la validación final de la
efectividad del modelo tendrá que venir del conjunto de prueba.

En el caso de aprender el comportamiento de un circuito tenemos una situación
única que no se da comúnmente en ML. Cuando el circuito es pequeño, se pueden
conocer todos sus posibles pares de entrada/salida. Por lo que en estos casos
se puede entrenar y validar el modelo con el conjunto completo de
entradas/salidas posibles del circuito.

\subsection{Modelos y técnicas}

En esta sección se explican los modelos más populares en aplicaciones de ALS,
así como los métodos utilizados para adaptarlos a este dominio.

\subsubsection{Árboles de decisión (DT)}

Un arbol de desición es una representación de una función que mapean un vector
de atributos a un solo valor de salida, una ``decisión''. Utilizando términos
que generalmente se utilizan para estructuras de grafo en forma de árbol, un
arbol de decisión llega a su decisión realizando una secuencia de pruebas,
iniciando en la raíz del árbol y siguiendo las ramas apropiadas hasta llegar a
una hoja. Cada nodo interno del árbol corresponde a una prueba del valor de uno
de sus atributos de entrada, las ramas del nodo son etiquetadas con los
posibles valores del atributo, y los nodos hoja corresponden con los valores
que puede retornar la función.

En el caso general, los valores de entrada y salida pueden ser discretos o
continuos. Cuando las entradas son valores discretos y las salidas solo pueden
tener dos valores, falso o verdadero, se le llama clasificación Booleana
\cite{russell2016artificial}.

En la Figura \ref{fig:DT} se puede observar la estructura de un árbol de
decisión booleano.

\begin{figure}[htb]
  \centering
  \includesvg[width=0.55\linewidth]{./imágenes/DT.svg}
  \caption{Árbol de decisión booleano con tres variables de entrada. El nodo
    naranja es la raíz del árbol, los nodos azules los nodos intermedios y los
    nodos verdes son las hojas del árbol, los cuales representan la decisión a la
  que llega.}
  \label{fig:DT}
\end{figure}

En el caso de aprender el comportamiento de un circuito nos enfrentamos a un
problema de clasificación booleana: dependiendo de las entradas del circuito,
cuál debe ser la salida. Por esto es que, dentro del contexto de ALS, son de
particular interés lo árboles de decisión booleanos.

Para transformar un modelo DT booleano a una expresión booleana que puede ser
expresada con componentes de un circuito se puede emplear el teorema de
expansión de Boole \cite{boole_investigation_1854}. Aplicando este teorema al
árbol de la figura \ref{fig:DT}, este se puede representar con la expresión
booleana $(\bar{X}Y) + (XY\bar{Z})$. Un árbol de decisiones no necesariamente
se encontrará en la configuración más optima para expresar la función booleana
que implementa, en el caso de de la Figura \ref{fig:DT} la expresión que
obtuvimos se puede simplificar más para obtener $Y(\bar{X} + \bar{Z})$. Por
este motivo, se recomienda aplicar técnicas de simplificación a la expresión
booleana o al circuito derivado de ella.

Un solo DT booleano tiene una sola salida, por lo que para circuitos con
múltiples salidas se debe de aplicar un DT que aprenda la función individual de
cada salida del circuito.

\subsubsection{Bosque aleatorio (RF)}

Es común crear modelos que son colecciones de hipótesis y combinar las
predicciones de cada hipótesis, puede escogerse un promedio de las
predicciones, tratarlas como un voto de mayoría o aplicar otras técnicas de ML
para obtener el resultado final. A las hipótesis individuales se les llama
modelo base y su combinación modelo de conjunto.
Crear estos modelos de conjunto puede ser beneficioso para disminuir el
sobreajuste y sesgo del modelo base.
Los bosques aleatorios son de los modelos de conjunto más comúnmente aplicados,
son formados por DTs como modelo base. \cite{russell2016artificial}

En el caso de un RF conformado por DTs booleanos, se determina la salida del
bosque con un voto de mayoría por parte de los árboles. Para implementar este
voto por mayoría en un circuito se pueden utilizador sumadores y un comparador.

\subsubsection{Perceptrón multicapa / Red neuronal}

Las redes neuronales tienen sus orígenes en \cite{mcculloch_logical_1943},
donde con inspiración biológica se intentó modelar la red de neurones en el
cerebro con circuitos computacionales. A pesar de sus orígenes, al utilizar
redes neuronales en el contexto de ML el realismo biológico impondría
restricciones innecesarias que limitarían su practicalidad. Por esto en la
actualidad las redes neuronales no se tratan como un modelo biológicos, sino
que son de interés como modelos puramente estadísticos para el reconocimiento
de patrones.

Existen muchos modelos de redes neuronales, pero uno de particular interés es
el perceptrón multicapa. Este uno de los tipos de red neuronal más conocida y
utilizada \cite{popescu_multilayer_2009}.

La arquitectura de perceptrón multicapa se caracteriza por formar un grafo
acíclico dirigido de nodos llamados neuronas artificiales. Los nodos se
organizan en capas, como se puede observar en la Figura \ref{fig:MLP}. Hay
capas de nodos designadas de entrada y de salida, cada nodo le aplica un
procesamiento a sus entradas y pasa los valores resultantes a sus sucesores en
la red.

Típicamente, el procesamiento de cada nodo es tomar una suma ponderada de sus
nodos predecesores y aplicarle una función de activación, la cual en
perceptrones multicapa modernos es continua y no lineal. Sea $a_j$ la salida
del nodo $j$ y sea $w_{i,j}$ el factor de ponderación para la conexión entre el
nodo $i$ y el nodo $j$; entonces se tiene

$$a_j = g_j\left(\sigma_i w_{i,j} a_i \right),$$

donde $g_j$ es la función de activación no lineal del nodo $j$.
\cite{russell2016artificial}

\begin{figure}[htb]
  \centering
  \includesvg[width=0.35\linewidth]{./imágenes/MLP.svg}
  \caption{Estructura general de un perceptrón multicapa con salidas booleanas.
  Puede llegar a tener más capas intermedias. La salida se decide típicamente
  interpretando el valor de cada nodo de salida como un valor de confianza de
  que esa sea la salida y se escoge la salida con un mayor valor.}
  \label{fig:MLP}
\end{figure}

Para profundizar en el tema del funcionamiento y entrenamiento de perceptrones
multicapa, se recomienda consultar el Capítulo 5 de \cite{bishop_pattern_2006}.

No es fácil traducir MLPs booleanos a circuitos. Un método sencillo es
sintetizar módulos aritméticos para realizar las computaciones necesarias, como
sumadores y multiplicadores. Sin embargo, esto resulta en circuitos muy grandes
\cite{miyasaka_logic_2021}. En \cite{rai_logic_2021}, el equipo 3 utiliza un
método donde podan conexiones de baja importancia para reducir el tamaño de la
red y cada nodo del MLP es transformado en una LUT a través de cuantización de
su salida, evitando utilizar circuitos aritméticos complejos. Se recomienda
leer el apéndice de la referencia para más detalles.

\subsubsection{Programación genética cartesiana (CGP)}

El término CGP aparece originalmente en \cite{miller_empirical_1999} como un
método de programación genética para aprender funciones booleanas. El cromosoma
utilizado por el algoritmo representa una matriz rectangular de funciones
primitivas con sus respectivas conexiones y funcionalidades, lo cual constituye
una representación de un circuito. Se le denomina ``cartesiana'' porque
organiza los nodos en una rejilla bidimensional identificada mediante
coordenadas cartesianas.

Un gran beneficio de CGP es que el proceso evolutivo puede empezar desde un
circuito aleatorio o uno predefinido, lo que permite trabajar a partir de
circuitos encontrados por otros métodos \cite{berndt_cgp-based_2022}. Esto lo
hace fácil de combinar con técnicas existentes. Otra ventaja es que su
cromosoma ya representa directamente un circuito, por lo que convertirlo en uno
es un proceso simple.

\section{Computación Aproximada}

\subsection{Síntesis Lógica Aproximada}

Definición y características

\subsection{Métodos clásicos}

Principios teóricos

\subsection{Métricas de error}

\subsection{Síntesis de modelos de ML}

\subsubsection{Diagramas de decisión binarios}

\subsubsection{Bosques de decisión}

\subsubsection{Redes neuronales}
