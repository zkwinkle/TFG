\chapter{Marco de referencia teórico}

Este capítulo introduce los conceptos teóricos necesarios para respaldar este
proyecto, el cual se sitúa en la intersección entre las áreas de ALS y ML. La
integración de estas disciplinas permite explorar nuevos métodos para la
generación de circuitos digitales que intercambien exactitud por eficiencia y
complejidad.

Se revisan los conceptos básicos de la computación aproximada y las técnicas
tradicionales de ALS, con el objetivo de contrastarlas con los enfoques basados
en ML. Luego se introducen conceptos fundamentales de ML, necesarios para
entender los mecanismos mediante los cuales un modelo puede ser útil en la
generación de circuitos aproximados, siendo especialmente relevante su
capacidad para aprender y generalizar funciones booleanas. Finalmente, se
abordan las técnicas de ML más valiosos en la aplicación de ALS, junto con
los métodos para transformar los modelos de ML a circuitos lógicos, paso
comúnmente necesario para su aplicación práctica dentro del marco de ALS.

La Figura \ref{fig:mapa_conceptual} mapea los conceptos tratados en
este capítulo en un mapa conceptual.

\begin{figure}[ht]
  \centering
  \includesvg[width=0.85\linewidth]{./imágenes/Mapa conceptual.svg}
  \caption{Mapa conceptual de los temas abordados en el marco teórico. Las
    burbujas rojas corresponden a temas asociados a ML, las burbujas azules
    corresponden a temas asociados a ALS y las burbujas moradas corresponden a
  temas que integran las 2 áreas.}
  \label{fig:mapa_conceptual}
\end{figure}

\section{Computación aproximada}

En esta sección se explican los conceptos de computación aproximada más
fundamentales para este trabajo.

La computación aproximada surgió como un paradigma para diseñar sistemas
digitales más eficientes en consumo de energía y rendimiento. Muchos sistemas y
aplicaciones son tolerantes a errores en los resultados computados; por
ejemplo, el procesamiento multimedia (audio, video, gráficos e imágenes), el
reconocimiento de patrones y la minería de datos. Al relajar la necesidad de
realizar operaciones exactas y determinísticas, las técnicas de computación
aproximada permiten mejorar significativamente la eficiencia de los circuitos.
\cite{han_approximate_2013}

Se denomina circuito aproximado a este tipo de circuito digital que sacrifica
precisión en sus resultados a cambio de una mayor eficiencia en su rendimiento,
área, consumo de potencia o una combinación de estas métricas.

\subsection{Síntesis lógica aproximada}

La construcción automática de circuitos digitales aproximados se realiza
mediante herramientas de diseño asistido por computador (Computer-Aided Design,
CAD), disponibles en entornos de diseño electrónico automatizado (Electronic
Design Automation, EDA). ALS se enfoca en mejorar el comportamiento de un
circuito (ya sea en consumo de potencia, área o rendimiento) sin necesidad de
conocer sus detalles de implementación. Este proceso se lleva a cabo de forma
sistemática, modificando la funcionalidad especificada sin exceder un umbral de
error predefinido \cite{ammes_two-level_2022}.

Existen métodos para crear circuitos aproximados manualmente, que no caen
dentro de la categoría de ALS, ya que no son automáticos. Este tipo de diseño
requiere un profundo conocimiento del comportamiento del circuito para poder
hacer aproximaciones que no degraden demasiado su precisión. Este nivel alto de
pericia requerida sobre la topología del circuito a aproximar es la principal
desventaja de estos métodos y el porqué en los últimos años la investigación se
ha enfocado hacia métodos de ALS.
\cite{ammes_two-level_2022}

Los métodos de optimización de circuitos digitales se suelen dividir en métodos
para dos o para múltiples niveles de profundidad lógica. En este caso la
profundidad lógica hace referencia a la cantidad máxima de compuertas lógicas
AND u OR por las que debe pasar una señal de la entrada a la salida del
circuito \cite{barr_investigation_1960}.

Ya que los circuitos de dos niveles tienen una profundidad lógica fija, su
optimización se enfoca en reducir la cantidad de operaciones en la
representación de suma de productos (Sum Of Products, SOP) del circuito. Para
circuitos de múltiples niveles, el objetivo de optimización depende de la
estructura booleana utilizada para representarlos y optimizarlos, pero los
métodos suelen buscar reducir el número de compuertas lógicas y la profundidad
del circuito. Los métodos de ML se destacan en este contexto, ya que pueden
manejar circuitos de profundidad arbitraria y son particularmente útiles para
optimizar circuitos complejos, lo que los convierte en una herramienta valiosa
para la optimización multi-nivel \cite{ammes_two-level_2022}.

En este contexto, en los últimos años se ha explorado con gran éxito la
aplicación de técnicas de ML para ALS \cite{pasandi_approximate_2019,
rai_logic_2021, berndt_review_2022, prats_ramos_impact_2024}. Gracias a su
capacidad de generalizar funciones, el aprendizaje de funciones booleanas ha
sido una de las técnicas de ML más exploradas y útiles para la generación de
circuitos aproximados. Esta efectividad se debe a que, al aprender una función,
el modelo busca cubrir todas las posibles soluciones de manera eficiente. Así,
logra un buen equilibrio entre precisión y rendimiento, lo que permite crear
circuitos eficientes sin perder demasiada exactitud.

\subsection{Métricas de error}

Independientemente de la metodología utilizada para ALS, es necesario definir
una manera de calcular el error insertado en la síntesis.

Existen dos categorías principales de métricas: de propósito general, que están
relacionadas con la ocurrencia del error, y métricas aritméticas, que están
relacionadas con la magnitud del error.

Algunos métodos de ALS calculan el error introducido de manera exacta, mientras
que otros lo estiman de manera aproximada. Los métodos para calcularlo de
manera exacta suelen ser más complejos y se pueden basar en el problema de
satisfaciabilidad booleana, diagramas de decisión binarios (Binary Decision
Diagram, BDD), álgebra simbólica computacional o incluso revisar todas las
posibles combinaciones de entradas, con tablas de verdad o simulaciones
exhaustivas. La estimación aproximada del error se suele implementar aplicando
simulaciones Monte Carlo, pero existen otras técnicas
\cite{ammes_two-level_2022}. De particular interés para este trabajo, se han
aplicado técnicas de ML para la estimación de error de manera aproximada; por
ejemplo, en \cite{pasandi_deep-powerx_2020} entrenan un modelo de DL para
predecir el error en las salidas primarias de un circuito al quitar o
reemplazar compuertas lógicas en la red del circuito.

La decisión de cuál metodología utilizar para el cálculo de error debe tomar en
cuenta el balance entre la calidad de los resultados y el esfuerzo
computacional. Un cálculo de error preciso suele resultar en mejores circuitos
aproximados, porque lleva a mejores decisiones de cuáles aproximaciones aplicar
durante el proceso de ALS. Sin embargo, un cálculo preciso puede presentar
costos computacionales altos, especialmente al ejecutarlos sobre cada posible
modificación a la topología del circuito \cite{ammes_two-level_2022}. Además,
el costo computacional suele crecer exponencialmente con la complejidad y la
cantidad de entradas del circuito.

El resto de esta sección introducirá algunas de las métricas de error más
comúnmente utilizadas para ALS. Se definen a continuación la notación y variables:

\begin{itemize}
  \item $n$: Cantidad de bits de entrada del circuito.
  \item $N$: Cantidad de combinaciones de entradas consideradas.
  \item $f(x)$: Salida del circuito original.
  \item $f'(x)$: Salida del circuito aproximado.
  \item $f_i(x)$: Bit de salida en la posición $i$ del circuito original.
  \item $f'_i(x)$: Bit de salida en la posición $i$ del circuito aproximado.
  % comentado porque se salía esta 1 línea de la página.
  % TODO: Agregar si llega a caber todo en la página.
  % \item $N = 2^n$: Valor de $N$ cuando se consideran todas las posibles combinaciones de entradas del circuito.
\end{itemize}

\subsubsection{Tasa de error}

La tasa de error (Error Rate, ER) corresponde con la probabilidad de observar
uno o más bits erróneos en la salida. ER es la métrica más comúnmente utilizada
en la aproximación de circuitos, siendo aplicada en circuitos tanto generales
como aritméticos \cite{ammes_two-level_2022}. El cálculo del ER se presenta en
la ecuación (\ref{eq:ER}),

\begin{equation} \label{eq:ER}
  ER = \frac{1}{N} \sum_{\forall x \in N} f(x) \neq f'(x).
\end{equation}

\subsubsection{Distancia de Hamming promedio}

La distancia de Hamming promedio (Mean Hamming Distance, MHD), también llamada
tasa de error de bits, representa la cantidad de bits de salida erróneos en
promedio. Esta tasa fue propuesta como una variación de ER para evaluar
aproximaciones con múltiples salidas. El cálculo del MHD se presenta en la
ecuación (\ref{eq:MHD}),

\begin{equation} \label{eq:MHD}
  MHD = \frac{1}{N} \sum_{\forall x \in N} \sum_{i=0}^{n-1} f_i(x) \oplus f'_i(x).
\end{equation}

\subsubsection{Peor distancia de Hamming}

La peor distancia de Hamming (Worst Hamming Distance, WHD) representa la mayor
distancia de Hamming entre las salidas originales y las aproximadas. Se utiliza
para verificar cuál es el peor caso en cantidad de bits de salida erróneos. El
cálculo del WHD se presenta en la ecuación (\ref{eq:WHD}),

\begin{equation} \label{eq:WHD}
  WHD = \max_{\forall x \in N} \sum_{i=0}^{n-1} f_i(x) \oplus f'_i(x).
\end{equation}

\subsubsection{Error en el peor caso}

El error en el peor caso (Worst Case Error, WCE) representa la mayor diferencia
absoluta en magnitud entre las salidas del circuito original y el aproximado.
Es la métrica más comúnmente utilizada en el diseño aritmético
\cite{ammes_two-level_2022}. El cálculo del WCE se presenta en la ecuación
(\ref{eq:WHD}),

\begin{equation} \label{eq:WCE}
  WHD = \max_{\forall x \in N} \left| f(x) - f'(x) \right|.
\end{equation}

\subsubsection{Error absoluto medio}

El error absoluto medio (Mean Absolute Error, MAE) representa la diferencia en
magnitud media entre las salidas del circuito original y el aproximado. El
cálculo del MAE se presenta en la ecuación (\ref{eq:MAE}),

\begin{equation} \label{eq:MAE}
  MAE = \frac{1}{N} \sum_{\forall x \in N} \left| f(x) - f'(x) \right|.
\end{equation}

\subsubsection{Error relativo medio}

El error relativo medio (Mean Relative Error, MRE) es similar al MAE, pero el
resultado se presenta como un porcentaje y es relativo a las salidas del
circuito original. Formalmente, representa la diferencia en magnitud media
relativa entre las salidas del circuito original y el aproximado. La ventaja de
utilizar un método de error relativo es que, como el valor de error es un
porcentaje, es posible analizar circuitos con cantidades de entradas
diferentes.

El cálculo del MRE se presenta en la ecuación (\ref{eq:MRE}). Se nota que si
$f(x)$ tiene un valor de $0$, la ecuación se vuelve indefinida; por lo tanto,
para aplicaciones prácticas se recomienda reemplazar el divisor con la función
$\max \left( 1, \left| f(x) \right| \right)$.

\begin{equation} \label{eq:MRE}
  MRE = \frac{1}{N} \sum_{\forall x \in N} \frac{ \left| f(x) - f'(x) \right| }{ \left| f(x) \right| }
\end{equation}

\subsubsection{Error cuadrático medio}

El error cuadrático medio (Mean Squared Error, MSE) representa la diferencia en
magnitud cuadrática media entre las salidas del circuito original y el
aproximado. Se presenta su cálculo en la ecuación (\ref{eq:MSE}). Aunque el MAE
suele ser más intuitivo de interpretar, el MSE ofrece una visión más completa,
ya que corresponde con el concepto de varianza de los errores. Además, el MSE
es computacionalmente menos costoso de calcular, lo que lo hace especialmente
útil cuando se están manejando grandes cantidades de datos.

\begin{equation} \label{eq:MSE}
  MSE = \frac{1}{N} \sum_{\forall x \in N} \left( f(x) - f'(x) \right)^2
\end{equation}

\section{Aprendizaje automático}

Según Russel y Norvig \cite{russell2016artificial}, en el aprendizaje
automático una computadora analiza datos, construye un modelo basado en esos
datos y luego usa ese modelo tanto como una hipótesis sobre el mundo como una
herramienta de software para resolver problemas.

En el contexto de ALS, una de las formas que más nos interesa aplicar ML es
que la computadora analice los datos de la tabla de verdad de un circuito,
de modo que se construya una representación generalizada del comportamiento de
dicho circuito.
Este modelo actúa como una hipótesis sobre lo que haría el circuito original, y
aunque normalmente en otros enfoques de ML se mantendría como una solución en
software, en nuestro caso buscamos transformarlo en hardware. De esta forma, el
modelo sigue funcionando como una hipótesis de lo que haría el circuito
original, pero implementada directamente como un circuito aproximado.

\subsection{Aprendizaje supervisado}

En el aprendizaje supervisado, el agente observa parejas de entradas y salidas
y aprende una función que mapea las entradas a sus correspondientes salidas
\cite{russell2016artificial}.

Es decir, en el aprendizaje supervisado, se dispone de los datos del
comportamiento que se desea aprender antes del entrenamiento.

Un ejemplo de esto, en el contexto de ALS, es cuando se entrena un modelo
utilizando la tabla de verdad de un circuito, que es un conjunto de datos que
muestra las salidas correspondientes a sus entradas.

\subsection{Aprendizaje reforzado}

El aprendizaje reforzado (Reinforcement Learning, RL) es aprender qué hacer o
cómo asociar situaciones con acciones, para maximizar una señal de recompensa.
No se le dice al agente qué acciones tomar, sino que debe descubrir cuáles
acciones dan la mayor recompensa mediante prueba y error.
\cite{sutton_reinforcement_2018}

En el contexto de ALS, un agente RL podría ser entrenado para aprender a
modificar un circuito, realizando modificaciones y recibiendo una recompensa
basada en parámetros como la reducción en área, en tiempo de ejecución, o el
aumento en el error del circuito. Así el agente, después de mucho entrenamiento
se convertirá en un experto en realizar modificaciones a circuitos para generar
versiones aproximadas de ellos.

\subsection{Generalización}

Según Bishop \cite{bishop_pattern_2006}, en el contexto de ML, la
generalización es la capacidad de un modelo para producir respuestas correctas
ante entradas no vistas durante el entrenamiento. En la práctica, el espacio de
posibles entradas suele ser tan amplio que el conjunto de entrenamiento solo
representa una pequeña fracción del total.

Por ejemplo, un modelo entrenado para distinguir entre fotos de gatos y perros
no puede haber visto todas las imágenes de estos animales en la existencia;
debe aprender patrones generales (es decir, debe generalizar), para poder
clasificar imágenes nuevas.

En el contexto de la síntesis lógica aproximada (ALS), si bien es posible
generar todas las combinaciones de entrada/salida de la tabla de verdad para
circuitos pequeños, esto se vuelve inviable a medida que el número de entradas
crece. Un circuito con 64 bits de entrada tiene $2^{64}$ combinaciones
posibles, aproximadamente \num{1.8e19}, lo que hace imposible utilizar su tabla
de verdad completa. Por tanto, el modelo debe aprender a generalizar a partir
de un subconjunto representativo. Incluso en circuitos pequeños, donde es
posible entrenar modelos con una tabla de verdad exhaustiva, el modelo no
memoriza los datos, sino que generaliza al construir una representación
abstracta del circuito basada en patrones presentes en los ejemplos.

\subsection{Sobreajuste}

Se dice que una función aprendida tiene sobreajuste cuando presta demasiada
atención al conjunto de datos con el que fue entrenada, lo que provoca un mal
desempeño con datos no vistos \cite{russell2016artificial}.

En el contexto de aprendizaje de circuitos, el sobreajuste puede ocurrir si un
modelo memoriza las entradas y salidas de un subconjunto limitado de la tabla
de verdad, sin capturar el comportamiento general del circuito. Como resultado,
puede fallar al predecir correctamente salidas para combinaciones de entrada no
vistas, aunque estas sigan la misma lógica.

\subsection{Validación de modelos}

La validación de modelos es el proceso de confirmar que un modelo produce
resultados suficientemente correctos para el propósito con el que fue diseñado,
dentro del dominio en el que se aplica \cite{schlesinger_terminology_1979}.

En el dominio de ML, esta validación comúnmente se lleva a cabo separando los
datos de entrenamiento en 3 conjuntos:

\begin{itemize}
  \item Un conjunto de entrenamiento, utilizado para entrenar los modelos
  \item Un conjunto de validación, que se utiliza para evaluar los modelos
    entrenados y ver que generalicen bien y no tengan sobreajuste. Se puede
    utilizar para entrenar múltiples modelos similares y escoger el que tenga
    mejor rendimiento.
  \item Un conjunto de prueba para realizar una evaluación final e imparcial
    del modelo \cite{russell2016artificial}.
\end{itemize}

A pesar de los nombres utilizados para los conjuntos, la validación final de la
efectividad del modelo tendrá que venir del conjunto de prueba.

En el caso de aprender el comportamiento de un circuito tenemos una situación
única que no se da comúnmente en ML. Cuando el circuito es pequeño, se pueden
conocer todos sus posibles pares de entrada/salida. Por lo que en estos casos
se puede entrenar y validar el modelo con el conjunto completo de
entradas/salidas posibles del circuito.

\subsection{Modelos y técnicas}

En esta sección se explican los modelos más populares en aplicaciones de ALS,
así como los métodos utilizados para adaptarlos a este dominio.

\subsubsection{Árboles de decisión (DT)}

Un árbol de decisión es una representación de una función que mapean un vector
de atributos a un solo valor de salida, una ``decisión''. Utilizando términos
que generalmente se utilizan para estructuras de grafo en forma de árbol, un
árbol de decisión llega a su decisión realizando una secuencia de pruebas,
iniciando en la raíz del árbol y siguiendo las ramas apropiadas hasta llegar a
una hoja. Cada nodo interno del árbol corresponde a una prueba del valor de uno
de sus atributos de entrada, las ramas del nodo son etiquetadas con los
posibles valores del atributo, y los nodos hoja corresponden con los valores
que puede retornar la función.

En el caso general, los valores de entrada y salida pueden ser discretos o
continuos. Cuando las entradas son valores discretos y las salidas solo pueden
tener dos valores, falso o verdadero, se le llama clasificación Booleana
\cite{russell2016artificial}.

En la Figura \ref{fig:DT} se puede observar la estructura de un árbol de
decisión booleano.

\begin{figure}[htb]
  \centering
  \includesvg[width=0.55\linewidth]{./imágenes/DT.svg}
  \caption{Árbol de decisión booleano con tres variables de entrada. El nodo
    naranja es la raíz del árbol, los nodos azules los nodos intermedios y los
    nodos verdes son las hojas del árbol, los cuales representan la decisión a la
  que llega.}
  \label{fig:DT}
\end{figure}

En el caso de aprender el comportamiento de un circuito nos enfrentamos a un
problema de clasificación booleana: dependiendo de las entradas del circuito,
cuál debe ser la salida. Por esto es que, dentro del contexto de ALS, son de
particular interés los árboles de decisión booleanos.

Para transformar un modelo DT booleano a una expresión booleana que puede ser
expresada con componentes de un circuito se puede emplear el teorema de
expansión de Boole \cite{boole_investigation_1854}. Aplicando este teorema al
árbol de la Figura \ref{fig:DT}, este se puede representar con la expresión
booleana $(\bar{X}Y) + (XY\bar{Z})$. Un árbol de decisiones no necesariamente
se encontrará en la configuración más óptima para expresar la función booleana
que implementa, en el caso de la Figura \ref{fig:DT} la expresión que
obtuvimos se puede simplificar más para obtener $Y(\bar{X} + \bar{Z})$. Por
este motivo, se recomienda aplicar técnicas de simplificación a la expresión
booleana o al circuito derivado de ella.

Un solo DT booleano tiene una sola salida, por lo que para circuitos con
múltiples salidas se debe de aplicar un DT que aprenda la función individual de
cada salida del circuito.

\subsubsection{Bosque aleatorio (RF)}

Es común crear modelos que son colecciones de hipótesis y combinar las
predicciones de cada hipótesis, puede escogerse un promedio de las
predicciones, tratarlas como un voto de mayoría o aplicar otras técnicas de ML
para obtener el resultado final. A las hipótesis individuales se les llama
modelo base y su combinación modelo de conjunto.
Crear estos modelos de conjunto puede ser beneficioso para disminuir el
sobreajuste y sesgo del modelo base.
Los bosques aleatorios son de los modelos de conjunto más comúnmente aplicados,
son formados por DT como modelo base \cite{russell2016artificial}.

En el caso de un RF conformado por DT booleanos, se determina la salida del
bosque con un voto de mayoría por parte de los árboles. Para implementar este
voto por mayoría en un circuito se pueden utilizar sumadores y un comparador.

\subsubsection{Perceptrón multicapa / Red neuronal}

Las redes neuronales tienen sus orígenes en \cite{mcculloch_logical_1943},
donde con inspiración biológica se intentó modelar la red de neuronas en el
cerebro con circuitos computacionales. A pesar de sus orígenes, al utilizar
redes neuronales en el contexto de ML el realismo biológico impondría
restricciones innecesarias que limitarían su practicabilidad. Por esto en la
actualidad las redes neuronales no se tratan como un modelo biológico, sino
que son de interés como modelos puramente estadísticos para el reconocimiento
de patrones.

Existen muchos modelos de redes neuronales, pero uno de particular interés es
el perceptrón multicapa. Este uno de los tipos de red neuronal más conocida y
utilizada \cite{popescu_multilayer_2009}.

La arquitectura de perceptrón multicapa se caracteriza por formar un grafo
acíclico dirigido de nodos llamados neuronas artificiales. Los nodos se
organizan en capas, como se puede observar en la Figura \ref{fig:MLP}. Hay
capas de nodos designadas de entrada y de salida, cada nodo le aplica un
procesamiento a sus entradas y pasa los valores resultantes a sus sucesores en
la red. Estos valores eventualmente se propagan hasta los nodos de salida.

Típicamente, el procesamiento de cada nodo es tomar una suma ponderada de sus
nodos predecesores y aplicarle una función de activación, la cual en
perceptrones multicapa modernos es continua y no lineal. Sea $a_j$ la salida
del nodo $j$ y sea $w_{i,j}$ el factor de ponderación para la conexión entre el
nodo $i$ y el nodo $j$; entonces se tiene
$$a_j = g_j\left(\sigma_i w_{i,j} a_i \right),$$
donde $g_j$ es la función de activación no lineal del nodo $j$.
\cite{russell2016artificial}

En un perceptrón clasificador, los nodos de salida corresponden a las posibles
clases en las que se puede clasificar, como en el caso de salidas booleanas. Un
MLP con salidas booleanas actúa como un clasificador con posibles clases 1 o 0.
El valor que se propaga a las salidas típicamente se interpreta como un nivel
de confianza de que un nodo de salida representa la respuesta correcta, y se
selecciona el mayor de estos valores.

\begin{figure}[htb]
  \centering
  \includesvg[width=0.35\linewidth]{./imágenes/MLP.svg}
  \caption{Estructura general de un perceptrón multicapa con salidas booleanas.
    Puede llegar a tener más capas intermedias.}
  \label{fig:MLP}
\end{figure}

Para profundizar en el tema del funcionamiento y entrenamiento de perceptrones
multicapa, se recomienda consultar el Capítulo 5 de \cite{bishop_pattern_2006}.

No es fácil traducir MLP booleanos a circuitos. Un método sencillo es
sintetizar módulos aritméticos para realizar las computaciones necesarias, como
sumadores y multiplicadores. Sin embargo, esto resulta en circuitos muy grandes
\cite{miyasaka_logic_2021}. En \cite{rai_logic_2021}, el equipo 3 utiliza un
método donde podan conexiones de baja importancia para reducir el tamaño de la
red y cada nodo del MLP es transformado en una LUT a través de cuantización de
su salida, evitando utilizar circuitos aritméticos complejos. Se recomienda
leer el apéndice de la referencia para más detalles.

\subsubsection{Programación genética cartesiana (CGP)}

El término CGP aparece originalmente en \cite{miller_empirical_1999} como un
método de programación genética para aprender funciones booleanas. El cromosoma
utilizado por el algoritmo representa una matriz rectangular de funciones
primitivas con sus respectivas conexiones y funcionalidades, lo cual constituye
una representación de un circuito. Se le denomina ``cartesiana'' porque
organiza los nodos en una rejilla bidimensional identificada mediante
coordenadas cartesianas.

Un gran beneficio de CGP es que el proceso evolutivo puede empezar desde un
circuito aleatorio o uno predefinido, lo que permite trabajar a partir de
circuitos encontrados por otros métodos \cite{berndt_cgp-based_2022}. Esto lo
hace fácil de combinar con técnicas existentes. Otra ventaja es que su
cromosoma ya representa directamente un circuito, por lo que convertirlo en uno
es un proceso simple.
